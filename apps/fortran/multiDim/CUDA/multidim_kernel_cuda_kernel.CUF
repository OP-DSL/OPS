!
! auto-generated by ops_fortran.py
!
MODULE MULTIDIM_KERNEL_MODULE
USE OPS_FORTRAN_DECLARATIONS
USE OPS_FORTRAN_RT_SUPPORT

USE OPS_CONSTANTS
USE ISO_C_BINDING
USE CUDAFOR


INTEGER(KIND=4), constant :: xdim1_multidim_kernel
INTEGER(KIND=4):: xdim1_multidim_kernel_h  = -1
#define OPS_ACC_MD1(d,x,y) ((x)*2+(d)+(xdim1_multidim_kernel*(y)*2))

contains

!user function
attributes (device) subroutine multidim_kernel_gpu(val, idx)
  IMPLICIT NONE
  REAL(kind=8)   , DIMENSION(2) :: val
  INTEGER(kind=4), DIMENSION(2), INTENT(IN) :: idx

  val(OPS_ACC_MD1(1,0,0)) = idx(1)
  val(OPS_ACC_MD1(2,0,0)) = idx(2)
end subroutine



#undef OPS_ACC_MD1


!CUDA kernel function -- wrapper calling user kernel
attributes (global) subroutine multidim_kernel_wrap( &
& opsDat1Local, &
& idx, &
& dat1_base, &
& size1, size2 )
  IMPLICIT NONE
  real(8), DEVICE :: opsDat1Local(*)
  integer(4) arg1
  integer(4) idx(2),idx_local(2)
  integer(4), value :: dat1_base
  integer(4) start(2)
  integer(4) end(2)
  integer, value :: size1,size2
  integer n_x, n_y


  n_y = blockDim%y * (blockIdx%y-1) + threadIdx%y
  n_x = blockDim%x * (blockIdx%x-1) + threadIdx%x

  idx_local(1) = idx(1)+ n_x-1
  idx_local(2) = idx(2)+ n_y-1
  arg1 = (n_x-1) * 1*2 + (n_y-1) * 1*2 * xdim1_multidim_kernel
  IF ((n_x-1) < size1 .AND. (n_y-1) < size2) THEN
    call multidim_kernel_gpu( &
    & opsDat1Local(dat1_base+arg1), &
    & idx_local )


  ENDIF
end subroutine

!host subroutine
attributes (host) subroutine multidim_kernel_host( userSubroutine, block, dim, range, &
& opsArg1, &
& opsArg2)
  IMPLICIT NONE
  character(kind=c_char,len=*), INTENT(IN) :: userSubroutine
  type ( ops_block ), INTENT(IN) :: block
  integer(kind=4), INTENT(IN):: dim
  integer(kind=4)   , DIMENSION(dim), INTENT(IN) :: range

  type ( ops_arg )  , INTENT(IN) :: opsArg1
  real(8), DIMENSION(:), DEVICE, ALLOCATABLE  :: opsDat1Local
  integer(kind=4) :: opsDat1Cardinality
  integer(kind=4), POINTER, DIMENSION(:)  :: dat1_size
  integer(kind=4) :: dat1_base
  INTEGER(KIND=4) :: xdim1
  INTEGER(KIND=4) :: multi_d1
  INTEGER(KIND=4) :: ydim1

  type ( ops_arg )  , INTENT(IN) :: opsArg2


  integer x_size, y_size
  integer start(2)
  integer end(2)
  integer, DEVICE :: idx(2)
  integer :: idx_h(2)
  integer(kind=4) :: n
  integer(kind=4) :: i10
  integer(kind=4) :: i20
  integer(kind=4) :: blocksPerGrid
  integer(kind=4) :: nshared
  integer(kind=4) :: nthread

  !cuda grid and thread block sizes
  type(dim3) :: grid, tblock

  type ( ops_arg ) , DIMENSION(2) :: opsArgArray

  opsArgArray(1) = opsArg1
  opsArgArray(2) = opsArg2

#ifdef OPS_MPI
  IF (getRange(block, start, end, range) < 0) THEN
    return
  ENDIF
#else
  DO n = 1, 2
    start(n) = range(2*n-1)
    end(n) = range(2*n)
  END DO
#endif

#ifdef OPS_MPI
  call getIdx(block,start,idx_h)
  idx = idx_h
#else
  idx(1) = start(1)
  idx(2) = start(2)
#endif


  x_size = MAX(0,end(1)-start(1)+1)
  y_size = MAX(0,end(2)-start(2)+1)

  call c_f_pointer(getDatSizeFromOpsArg(opsArg1),dat1_size,(/dim/))
  xdim1 = dat1_size(1)
  ydim1 = dat1_size(2)
  opsDat1Cardinality = opsArg1%dim * xdim1 * ydim1
  multi_d1 = getDatDimFromOpsArg(opsArg1) ! dimension of the dat
  dat1_base = getDatBaseFromOpsArg2D(opsArg1,start,multi_d1)
  call c_f_pointer(opsArg1%data_d,opsDat1Local,(/opsDat1Cardinality/))


  IF ((xdim1 .NE. xdim1_multidim_kernel_h) ) THEN
    xdim1_multidim_kernel = xdim1
    xdim1_multidim_kernel_h = xdim1
  ENDIF

  grid = dim3( (x_size-1)/getOPS_block_size_x()+ 1, (y_size-1)/getOPS_block_size_y() + 1, 1)
  tblock = dim3(getOPS_block_size_x(),getOPS_block_size_y(),1)


  !halo exchanges
  call ops_H_D_exchanges_device(opsArgArray,2)
  call ops_halo_exchanges(opsArgArray,2,range)

  call multidim_kernel_wrap <<<grid,tblock>>> (&
  & opsDat1Local, &
  & idx, &
  & dat1_base, &
  & x_size, y_size )

  call ops_set_dirtybit_device(opsArgArray, 2)
  call ops_set_halo_dirtybit3(opsArg1,range)

end subroutine
END MODULE
