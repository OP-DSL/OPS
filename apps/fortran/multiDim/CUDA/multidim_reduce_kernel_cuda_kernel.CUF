!
! auto-generated by ops_fortran.py
!
MODULE MULTIDIM_REDUCE_KERNEL_MODULE
USE OPS_FORTRAN_DECLARATIONS
USE OPS_FORTRAN_RT_SUPPORT

USE OPS_CONSTANTS
USE ISO_C_BINDING
USE CUDAFOR

real(8), DIMENSION(:), DEVICE, ALLOCATABLE :: reductionArrayDevice2_multidim_reduce_kernel

INTEGER(KIND=4), constant :: xdim1_multidim_reduce_kernel
INTEGER(KIND=4):: xdim1_multidim_reduce_kernel_h  = -1
#define OPS_ACC_MD1(d,x,y) ((x)*2+(d)+(xdim1_multidim_reduce_kernel*(y)*2))

contains

!Multidimensional reduction cuda kernel
attributes (device) SUBROUTINE ReductionFloat8Mdim(sharedDouble8, reductionResult,inputValue,reductionOperation,dim)
  REAL(kind=8), DIMENSION(:), DEVICE :: reductionResult
  REAL(kind=8), DIMENSION(:) :: inputValue
  INTEGER(kind=4), VALUE :: reductionOperation
  INTEGER(kind=4), VALUE :: dim
  REAL(kind=8), DIMENSION(0:*) :: sharedDouble8
  INTEGER(kind=4) :: i1
  INTEGER(kind=4) :: d
  INTEGER(kind=4) :: threadID
  threadID = (threadIdx%y-1)*blockDim%x + (threadIdx%x - 1)
  i1 = ishft(blockDim%x*blockDim%y,-1)
  CALL syncthreads()
  sharedDouble8(threadID*dim:threadID*dim+dim-1) = inputValue(1:dim)
  DO WHILE (i1 > 0 )
    CALL syncthreads()
    IF (threadID < i1) THEN
      SELECT CASE(reductionOperation)
      CASE (0)
      DO i2 = 0, dim-1
        sharedDouble8(threadID*dim + i2) = sharedDouble8(threadID*dim + i2) + sharedDouble8((threadID + i1)*dim + i2)
      END DO
      CASE (1)
      DO i2 = 0, dim-1
        IF (sharedDouble8(threadID*dim + i2) < sharedDouble8((threadID + i1)*dim + i2)) THEN
          sharedDouble8(threadID*dim + i2) = sharedDouble8((threadID + i1)*dim + i2)
        ENDIF
      END DO
      CASE (2)
      DO i2 = 0, dim-1
        IF (sharedDouble8(threadID*dim + i2) < sharedDouble8((threadID + i1)*dim + i2)) THEN
          sharedDouble8(threadID*dim + i2) = sharedDouble8((threadID + i1)*dim + i2)
        ENDIF
      END DO
      END SELECT
    ENDIF
    i1 = ishft(i1,-1)
  END DO
  CALL syncthreads()
  IF (threadID .EQ. 0) THEN
    SELECT CASE(reductionOperation)
    CASE (0)
    reductionResult(1:dim) = reductionResult(1:dim) + sharedDouble8(0:dim-1)
    CASE (1)
    DO i2 = 1, dim
      IF (reductionResult(i2) < sharedDouble8(i2-1)) THEN
        reductionResult(i2) = sharedDouble8(i2-1)
      ENDIF
    END DO
    CASE (2)
    DO i2 = 1, dim
      IF (reductionResult(i2) > sharedDouble8(i2-1)) THEN
        reductionResult(i2) = sharedDouble8(i2-1)
      ENDIF
    END DO
    END SELECT
  ENDIF
  CALL syncthreads()
END SUBROUTINE

!Multidimensional reduction cuda kernel
attributes (device) SUBROUTINE ReductionInt4Mdim(sharedInt4, reductionResult,inputValue,reductionOperation,dim)
  INTEGER(kind=4), DIMENSION(:), DEVICE :: reductionResult
  INTEGER(kind=4), DIMENSION(:) :: inputValue
  INTEGER(kind=4), VALUE :: reductionOperation
  INTEGER(kind=4), VALUE :: dim
  INTEGER(kind=4), DIMENSION(0:*) :: sharedInt4
  INTEGER(kind=4) :: i1
  INTEGER(kind=4) :: d
  INTEGER(kind=4) :: threadID
  threadID = (threadIdx%y-1)*blockDim%x + (threadIdx%x - 1)
  i1 = ishft(blockDim%x*blockDim%y,-1)
  CALL syncthreads()
  sharedInt4(threadID*dim:threadID*dim+dim-1) = inputValue(1:dim)
  DO WHILE (i1 > 0 )
    CALL syncthreads()
    IF (threadID < i1) THEN
      SELECT CASE(reductionOperation)
      CASE (0)
      DO i2 = 0, dim-1
        sharedInt4(threadID*dim + i2) = sharedInt4(threadID*dim + i2) + sharedInt4((threadID + i1)*dim + i2)
      END DO
      CASE (1)
      DO i2 = 0, dim-1
        IF (sharedInt4(threadID*dim + i2) < sharedInt4((threadID + i1)*dim + i2)) THEN
          sharedInt4(threadID*dim + i2) = sharedInt4((threadID + i1)*dim + i2)
        ENDIF
      END DO
      CASE (2)
      DO i2 = 0, dim-1
        IF (sharedInt4(threadID*dim + i2) < sharedInt4((threadID + i1)*dim + i2)) THEN
          sharedInt4(threadID*dim + i2) = sharedInt4((threadID + i1)*dim + i2)
        ENDIF
      END DO
      END SELECT
    ENDIF
    i1 = ishft(i1,-1)
  END DO
  CALL syncthreads()
  IF (threadID .EQ. 0) THEN
    SELECT CASE(reductionOperation)
    CASE (0)
    reductionResult(1:dim) = reductionResult(1:dim) + sharedInt4(0:dim-1)
    CASE (1)
    DO i2 = 1, dim
      IF (reductionResult(i2) < sharedInt4(i2-1)) THEN
        reductionResult(i2) = sharedInt4(i2-1)
      ENDIF
    END DO
    CASE (2)
    DO i2 = 1, dim
      IF (reductionResult(i2) > sharedInt4(i2-1)) THEN
        reductionResult(i2) = sharedInt4(i2-1)
      ENDIF
    END DO
    END SELECT
  ENDIF
  CALL syncthreads()
END SUBROUTINE

!user function
attributes (device) subroutine multidim_reduce_kernel_gpu(val, redu_dat1)
  IMPLICIT NONE
  REAL   (kind=8), DIMENSION(2), INTENT(IN) :: val
  REAL(kind=8), DIMENSION(2) :: redu_dat1
  redu_dat1(1) = redu_dat1(1) + val(OPS_ACC_MD1(1,0,0))
  redu_dat1(2) = redu_dat1(2) + val(OPS_ACC_MD1(2,0,0))
end subroutine




#undef OPS_ACC_MD1


!CUDA kernel function -- wrapper calling user kernel
attributes (global) subroutine multidim_reduce_kernel_wrap( &
& opsDat1Local, &
& reductionArrayDevice2,   &
& dat1_base, &
& size1, size2 )
  IMPLICIT NONE
  real(8), DEVICE, INTENT(IN) :: opsDat1Local(*)
  integer(4) arg1
  real(8), DIMENSION(:), DEVICE :: reductionArrayDevice2
  real(8), DIMENSION(0:2-1) :: opsGblDat2Device
  real(8), DIMENSION(0:*), SHARED :: sharedMem
  integer(4), value :: dat1_base
  integer(4) start(2)
  integer(4) end(2)
  integer, value :: size1,size2
  integer n_x, n_y


  n_y = blockDim%y * (blockIdx%y-1) + threadIdx%y
  n_x = blockDim%x * (blockIdx%x-1) + threadIdx%x

  arg1 = (n_x-1) * 1*2 + (n_y-1) * 1*2 * xdim1_multidim_reduce_kernel
  opsGblDat2Device = 0.0_8
  IF ((n_x-1) < size1 .AND. (n_y-1) < size2) THEN
    call multidim_reduce_kernel_gpu( &
    & opsDat1Local(dat1_base+arg1), &
    & opsGblDat2Device )

  ENDIF

  call ReductionFloat8Mdim(sharedMem, reductionArrayDevice2(((blockIdx%z - 1)*gridDim%y*gridDim%x + (blockIdx%y - 1)*gridDim%x + (blockIdx%x-1))*(2) + 1:),opsGblDat2Device,0,2)

end subroutine

!host subroutine
attributes (host) subroutine multidim_reduce_kernel_host( userSubroutine, block, dim, range, &
& opsArg1, &
& opsArg2)
  use cudafor
  IMPLICIT NONE
  character(kind=c_char,len=*), INTENT(IN) :: userSubroutine
  type ( ops_block ), INTENT(IN) :: block
  integer(kind=4), INTENT(IN):: dim
  integer(kind=4)   , DIMENSION(dim), INTENT(IN) :: range
  real(kind=8) t1,t2,t3
  real(kind=4) transfer_total, transfer
  integer(kind=4) :: istat

  type ( ops_arg )  , INTENT(IN) :: opsArg1
  real(8), DIMENSION(:), DEVICE, POINTER  :: opsDat1Local
  integer(kind=4) :: opsDat1Cardinality
  integer(kind=4), POINTER, DIMENSION(:)  :: dat1_size
  integer(kind=4) :: dat1_base
  INTEGER(KIND=4) :: xdim1
  INTEGER(KIND=4) :: multi_d1
  INTEGER(KIND=4) :: ydim1

  type ( ops_arg )  , INTENT(IN) :: opsArg2
  integer(kind=4) :: opsDat2Cardinality
  real(8), DIMENSION(:), POINTER :: opsDat2Host
  real(8), DIMENSION(:), ALLOCATABLE :: reductionArrayHost2
  INTEGER(kind=4) :: reductionCardinality2

  integer x_size, y_size
  integer start(2)
  integer end(2)
  integer(kind=4) :: n
  integer(kind=4) :: i10
  integer(kind=4) :: i20
  integer(kind=4) :: blocksPerGrid
  integer(kind=4) :: nshared
  integer(kind=4) :: nthread

  !cuda grid and thread block sizes
  type(dim3) :: grid, tblock

  type ( ops_arg ) , DIMENSION(2) :: opsArgArray

  opsArgArray(1) = opsArg1
  opsArgArray(2) = opsArg2

  call setKernelTime(3,userSubroutine//char(0),0.0_8,0.0_8,0.0_4,0)
  call ops_timers_core(t1)

#ifdef OPS_MPI
  IF (getRange(block, start, end, range) < 0) THEN
    return
  ENDIF
#else
  DO n = 1, 2
    start(n) = range(2*n-1)
    end(n) = range(2*n)
  END DO
#endif


  x_size = MAX(0,end(1)-start(1)+1)
  y_size = MAX(0,end(2)-start(2)+1)

  call c_f_pointer(getDatSizeFromOpsArg(opsArg1),dat1_size,(/dim/))
  xdim1 = dat1_size(1)
  ydim1 = dat1_size(2)
  opsDat1Cardinality = opsArg1%dim * xdim1 * ydim1
  multi_d1 = getDatDimFromOpsArg(opsArg1) ! dimension of the dat
  dat1_base = getDatBaseFromOpsArg2D(opsArg1,start,multi_d1)
  call c_f_pointer(opsArg1%data_d,opsDat1Local,(/opsDat1Cardinality/))

  opsDat2Cardinality = opsArg2%dim
  call c_f_pointer(getReductionPtrFromOpsArg(opsArg2,block),opsDat2Host,(/opsDat2Cardinality/))

  IF ((xdim1 .NE. xdim1_multidim_reduce_kernel_h) ) THEN
    xdim1_multidim_reduce_kernel = xdim1
    xdim1_multidim_reduce_kernel_h = xdim1
  ENDIF

  grid = dim3( (x_size-1)/getOPS_block_size_x()+ 1, (y_size-1)/getOPS_block_size_y() + 1, 1)
  tblock = dim3(getOPS_block_size_x(),getOPS_block_size_y(),1)

  !Reduction vars and shared memory for reductions
  nshared = 0
  nthread = getOPS_block_size_x()*getOPS_block_size_y()
  blocksPerGrid = ((x_size-1)/getOPS_block_size_x()+ 1)*((y_size-1)/getOPS_block_size_y() + 1)* 1

  nshared = MAX(nshared,8*2*nthread)

  reductionCardinality2 = blocksPerGrid * 1
  allocate( reductionArrayHost2(reductionCardinality2* (2)) )
  IF (.not. allocated(reductionArrayDevice2_multidim_reduce_kernel)) THEN
    allocate( reductionArrayDevice2_multidim_reduce_kernel(reductionCardinality2* (2)) )
  ENDIF

  DO i10 = 0, reductionCardinality2-1
    reductionArrayHost2(i10 * (2) + 1 : i10 * (2) + (2)) = 0.0
  END DO

  reductionArrayDevice2_multidim_reduce_kernel = reductionArrayHost2

  !halo exchanges
  call ops_H_D_exchanges_device(opsArgArray,2)
  call ops_halo_exchanges(opsArgArray,2,range)
  call ops_H_D_exchanges_device(opsArgArray,2)

  call ops_timers_core(t2)
  call multidim_reduce_kernel_wrap <<<grid,tblock,nshared>>> (&
  & opsDat1Local, &
  & reductionArrayDevice2_multidim_reduce_kernel, &
  & dat1_base, &
  & x_size, y_size )

  reductionArrayHost2 = reductionArrayDevice2_multidim_reduce_kernel

  DO i10 = 0, reductionCardinality2-1
    opsDat2Host(1:2) = opsDat2Host(1:2) + reductionArrayHost2(i10 * (2) + 1 : i10 * (2) + (2))
  END DO

  deallocate( reductionArrayHost2 )
  istat = cudaDeviceSynchronize()
  call ops_timers_core(t3)
  call ops_set_dirtybit_device(opsArgArray, 2)

  !Timing and data movement
  transfer_total = 0.0_4
  call ops_compute_transfer(2, start, end, opsArg1,transfer)
  transfer_total = transfer_total + transfer
  call setKernelTime(3,userSubroutine,t3-t2,t2-t1,transfer_total,1)
end subroutine
END MODULE
