!
! auto-generated by ops_fortran.py
!
MODULE MULTIDIM_PRINT_KERNEL_MODULE
USE OPS_FORTRAN_DECLARATIONS
USE OPS_FORTRAN_RT_SUPPORT

USE OPS_CONSTANTS
USE ISO_C_BINDING
USE CUDAFOR


INTEGER(KIND=4), constant :: xdim1_multidim_print_kernel
INTEGER(KIND=4):: xdim1_multidim_print_kernel_h  = -1
INTEGER(KIND=4), constant :: ydim1_multidim_print_kernel
INTEGER(KIND=4):: ydim1_multidim_print_kernel_h  = -1
#define OPS_ACC_MD1(d,x,y,z) ((x)*3+(d)+(xdim1_multidim_print_kernel*(y)*3)+(xdim1_multidim_print_kernel*ydim1_multidim_print_kernel*(z)*3))

contains

!user function
attributes (device) subroutine multidim_print_kernel_gpu(val)
  IMPLICIT NONE
  REAL   (kind=8), DIMENSION(3) :: val



end subroutine




#undef OPS_ACC_MD1


!CUDA kernel function -- wrapper calling user kernel
attributes (global) subroutine multidim_print_kernel_wrap( &
& opsDat1Local, &
& dat1_base, &
& size1, size2, size3 )
  IMPLICIT NONE
  real(8), DEVICE, INTENT(IN) :: opsDat1Local(*)
  integer(4) arg1
  integer(4), value :: dat1_base
  integer(4) start(3)
  integer(4) end(3)
  integer, value :: size1,size2,size3
  integer n_x, n_y, n_z


  n_z = blockDim%z * (blockIdx%z-1) + threadIdx%z
  n_y = blockDim%y * (blockIdx%y-1) + threadIdx%y
  n_x = blockDim%x * (blockIdx%x-1) + threadIdx%x

  arg1 = (n_x-1) * 1*3 + (n_y-1) * 1*3 * xdim1_multidim_print_kernel + (n_z-1) * 1*3 * xdim1_multidim_print_kernel * ydim1_multidim_print_kernel
  IF ((n_x-1) < size1 .AND. (n_y-1) < size2 .AND. (n_z-1) < size3) THEN
    call multidim_print_kernel_gpu( &
    & opsDat1Local(dat1_base+arg1) )


  ENDIF
end subroutine

!host subroutine
attributes (host) subroutine multidim_print_kernel_host( userSubroutine, block, dim, range, &
& opsArg1)
  IMPLICIT NONE
  character(kind=c_char,len=*), INTENT(IN) :: userSubroutine
  type ( ops_block ), INTENT(IN) :: block
  integer(kind=4), INTENT(IN):: dim
  integer(kind=4)   , DIMENSION(dim), INTENT(IN) :: range
  real(kind=8) t1,t2,t3
  real(kind=4) transfer_total, transfer
  integer(kind=4) :: istat

  type ( ops_arg )  , INTENT(IN) :: opsArg1
  real(8), DIMENSION(:), DEVICE, ALLOCATABLE  :: opsDat1Local
  integer(kind=4) :: opsDat1Cardinality
  integer(kind=4), POINTER, DIMENSION(:)  :: dat1_size
  integer(kind=4) :: dat1_base
  INTEGER(KIND=4) :: xdim1
  INTEGER(KIND=4) :: multi_d1
  INTEGER(KIND=4) :: ydim1, zdim1


  integer x_size, y_size, z_size
  integer start(3)
  integer end(3)
  integer(kind=4) :: n
  integer(kind=4) :: i10
  integer(kind=4) :: i20
  integer(kind=4) :: blocksPerGrid
  integer(kind=4) :: nshared
  integer(kind=4) :: nthread

  !cuda grid and thread block sizes
  type(dim3) :: grid, tblock

  type ( ops_arg ) , DIMENSION(1) :: opsArgArray

  opsArgArray(1) = opsArg1

  call setKernelTime(2,userSubroutine//char(0),0.0_8,0.0_8,0.0_4,0)
  call ops_timers_core(t1)

#ifdef OPS_MPI
  IF (getRange(block, start, end, range) < 0) THEN
    return
  ENDIF
#else
  DO n = 1, 3
    start(n) = range(2*n-1)
    end(n) = range(2*n)
  END DO
#endif


  x_size = MAX(0,end(1)-start(1)+1)
  y_size = MAX(0,end(2)-start(2)+1)
  z_size = MAX(0,end(3)-start(3)+1)

  call c_f_pointer(getDatSizeFromOpsArg(opsArg1),dat1_size,(/dim/))
  xdim1 = dat1_size(1)
  ydim1 = dat1_size(2)
  zdim1 = dat1_size(3)
  opsDat1Cardinality = opsArg1%dim * xdim1 * ydim1 * zdim1
  multi_d1 = getDatDimFromOpsArg(opsArg1) ! dimension of the dat
  dat1_base = getDatBaseFromOpsArg3D(opsArg1,start,multi_d1)
  call c_f_pointer(opsArg1%data_d,opsDat1Local,(/opsDat1Cardinality/))

  IF ((xdim1 .NE. xdim1_multidim_print_kernel_h) .OR. &
  (ydim1 .NE. ydim1_multidim_print_kernel_h) ) THEN
    xdim1_multidim_print_kernel = xdim1
    xdim1_multidim_print_kernel_h = xdim1
    ydim1_multidim_print_kernel = ydim1
    ydim1_multidim_print_kernel_h = ydim1
  ENDIF

  grid = dim3( (x_size-1)/getOPS_block_size_x()+ 1, (y_size-1)/getOPS_block_size_y() + 1, z_size)
  tblock = dim3(getOPS_block_size_x(),getOPS_block_size_y(),1)


  !halo exchanges
  call ops_H_D_exchanges_device(opsArgArray,1)
  call ops_halo_exchanges(opsArgArray,1,range)

  call ops_timers_core(t2)
  call multidim_print_kernel_wrap <<<grid,tblock>>> (&
  & opsDat1Local, &
  & dat1_base, &
  & x_size, y_size, z_size )

  istat = cudaDeviceSynchronize()
  call ops_timers_core(t3)
  call ops_set_dirtybit_device(opsArgArray, 1)

  !Timing and data movement
  transfer_total = 0.0_4
  call ops_compute_transfer(3, start, end, opsArg1,transfer)
  transfer_total = transfer_total + transfer
  call setKernelTime(2,userSubroutine,t3-t2,t2-t1,transfer_total,1)
end subroutine
END MODULE
