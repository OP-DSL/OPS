//
// auto-generated by ops.py
//
#include "./OpenMP4/clover_leaf_common.h"

#define OPS_GPU

extern int xdim0_advec_mom_kernel_mass_flux_x;
extern int xdim1_advec_mom_kernel_mass_flux_x;

#undef OPS_ACC0
#undef OPS_ACC1

#define OPS_ACC0(x, y) (x + xdim0_advec_mom_kernel_mass_flux_x * (y))
#define OPS_ACC1(x, y) (x + xdim1_advec_mom_kernel_mass_flux_x * (y))

// user function

void advec_mom_kernel_mass_flux_x_c_wrapper(double *p_a0, int base0, int tot0,
                                            double *p_a1, int base1, int tot1,
                                            int x_size, int y_size) {
  int num_blocks = OPS_threads;
#pragma omp target enter data map(                                             \
    to : p_a0[0 : tot0], p_a1[0 : tot1], states[0 : number_of_states])
#ifdef OPS_GPU

#pragma omp target teams num_teams(num_blocks)                                 \
    thread_limit(OPS_threads_for_block)
#pragma omp distribute parallel for simd schedule(static, 1)
#endif
  for (int i = 0; i < y_size * x_size; i++) {
#ifdef OPS_GPU
#endif
    int n_x = i % x_size;
    int n_y = i / x_size;
    double *node_flux = p_a0 + base0 + n_x * 1 * 1 +
                        n_y * xdim0_advec_mom_kernel_mass_flux_x * 1 * 1;

    const double *mass_flux_x =
        p_a1 + base1 + n_x * 1 * 1 +
        n_y * xdim1_advec_mom_kernel_mass_flux_x * 1 * 1;

    node_flux[OPS_ACC0(0, 0)] =
        0.25 * (mass_flux_x[OPS_ACC1(0, -1)] + mass_flux_x[OPS_ACC1(0, 0)] +
                mass_flux_x[OPS_ACC1(1, -1)] + mass_flux_x[OPS_ACC1(1, 0)]);
  }
}
#undef OPS_ACC0
#undef OPS_ACC1
