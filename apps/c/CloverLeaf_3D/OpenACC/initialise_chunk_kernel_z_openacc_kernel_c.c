//
// auto-generated by ops.py
//

#define OPS_GPU

int xdim0_initialise_chunk_kernel_z;
int ydim0_initialise_chunk_kernel_z;
int xdim1_initialise_chunk_kernel_z;
int ydim1_initialise_chunk_kernel_z;
int xdim2_initialise_chunk_kernel_z;
int ydim2_initialise_chunk_kernel_z;

//user function
inline 
void initialise_chunk_kernel_z(ptr_double vertexz,
  const ptr_int zz,
  ptr_double vertexdz) {
  int z_min=field.z_min-2;

  double min_z, d_z;
  d_z = (grid.zmax - grid.zmin)/(double)grid.z_cells;
  min_z=grid.zmin+d_z*field.back;

  OPS_ACC(vertexz, 0,0,0) = min_z + d_z * (OPS_ACC(zz, 0,0,0) - z_min);
  OPS_ACC(vertexdz, 0,0,0) = (double)d_z;
}


void initialise_chunk_kernel_z_c_wrapper(
  double *p_a0,
  int *p_a1,
  double *p_a2,
  int x_size, int y_size, int z_size) {
  #ifdef OPS_GPU
  #pragma acc parallel deviceptr(p_a0,p_a1,p_a2)
  #pragma acc loop
  #endif
  for ( int n_z=0; n_z<z_size; n_z++ ){
    #ifdef OPS_GPU
    #pragma acc loop
    #endif
    for ( int n_y=0; n_y<y_size; n_y++ ){
      #ifdef OPS_GPU
      #pragma acc loop
      #endif
      for ( int n_x=0; n_x<x_size; n_x++ ){
        ptr_double ptr0 = {  p_a0 + n_x*0*1 + n_y*xdim0_initialise_chunk_kernel_z*0*1 + n_z*xdim0_initialise_chunk_kernel_z*ydim0_initialise_chunk_kernel_z*1*1, xdim0_initialise_chunk_kernel_z, ydim0_initialise_chunk_kernel_z};
        const ptr_int ptr1 = {  p_a1 + n_x*0*1 + n_y*xdim1_initialise_chunk_kernel_z*0*1 + n_z*xdim1_initialise_chunk_kernel_z*ydim1_initialise_chunk_kernel_z*1*1, xdim1_initialise_chunk_kernel_z, ydim1_initialise_chunk_kernel_z};
        ptr_double ptr2 = {  p_a2 + n_x*0*1 + n_y*xdim2_initialise_chunk_kernel_z*0*1 + n_z*xdim2_initialise_chunk_kernel_z*ydim2_initialise_chunk_kernel_z*1*1, xdim2_initialise_chunk_kernel_z, ydim2_initialise_chunk_kernel_z};
        initialise_chunk_kernel_z( ptr0,
          ptr1,
          ptr2 );

      }
    }
  }
}
