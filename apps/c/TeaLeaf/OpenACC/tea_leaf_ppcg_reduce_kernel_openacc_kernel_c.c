//
// auto-generated by ops.py
//

#define OPS_GPU

int xdim0_tea_leaf_ppcg_reduce_kernel;
int xdim1_tea_leaf_ppcg_reduce_kernel;
int xdim2_tea_leaf_ppcg_reduce_kernel;


#undef OPS_ACC0
#undef OPS_ACC1
#undef OPS_ACC2


#define OPS_ACC0(x,y) (x+xdim0_tea_leaf_ppcg_reduce_kernel*(y))
#define OPS_ACC1(x,y) (x+xdim1_tea_leaf_ppcg_reduce_kernel*(y))
#define OPS_ACC2(x,y) (x+xdim2_tea_leaf_ppcg_reduce_kernel*(y))

//user function
inline 
void tea_leaf_ppcg_reduce_kernel(const double *rstore, const double *r, const double *z, double *rnn) {
  *rnn = *rnn + (r[OPS_ACC1(0,0)] - rstore[OPS_ACC0(0,0)]) * z[OPS_ACC2(0,0)];
}


#undef OPS_ACC0
#undef OPS_ACC1
#undef OPS_ACC2



void tea_leaf_ppcg_reduce_kernel_c_wrapper(
  double *p_a0,
  double *p_a1,
  double *p_a2,
  double *p_a3,
  int x_size, int y_size) {
  double p_a3_0 = p_a3[0];
  #ifdef OPS_GPU
  #pragma acc parallel deviceptr(p_a0,p_a1,p_a2) reduction(+:p_a3_0)
  #pragma acc loop reduction(+:p_a3_0)
  #endif
  for ( int n_y=0; n_y<y_size; n_y++ ){
    #ifdef OPS_GPU
    #pragma acc loop reduction(+:p_a3_0)
    #endif
    for ( int n_x=0; n_x<x_size; n_x++ ){
      tea_leaf_ppcg_reduce_kernel(  p_a0 + n_x*1*1 + n_y*xdim0_tea_leaf_ppcg_reduce_kernel*1*1,
           p_a1 + n_x*1*1 + n_y*xdim1_tea_leaf_ppcg_reduce_kernel*1*1, p_a2 + n_x*1*1 + n_y*xdim2_tea_leaf_ppcg_reduce_kernel*1*1,
           &p_a3_0 );

    }
  }
  p_a3[0] = p_a3_0;
}
