//
// auto-generated by ops.py
//

#define OPS_GPU

int xdim0_tea_leaf_ppcg_reduce_kernel;
int xdim1_tea_leaf_ppcg_reduce_kernel;
int xdim2_tea_leaf_ppcg_reduce_kernel;

#undef OPS_ACC0
#undef OPS_ACC1
#undef OPS_ACC2

#define OPS_ACC0(x, y) (x + xdim0_tea_leaf_ppcg_reduce_kernel * (y))
#define OPS_ACC1(x, y) (x + xdim1_tea_leaf_ppcg_reduce_kernel * (y))
#define OPS_ACC2(x, y) (x + xdim2_tea_leaf_ppcg_reduce_kernel * (y))

// user function
inline void tea_leaf_ppcg_reduce_kernel(const double *rstore, const double *r,
                                        const double *z, double *rnn) {
  *rnn =
      *rnn + (r[OPS_ACC1(0, 0)] - rstore[OPS_ACC0(0, 0)]) * z[OPS_ACC2(0, 0)];
}

#undef OPS_ACC0
#undef OPS_ACC1
#undef OPS_ACC2

void tea_leaf_ppcg_reduce_kernel_c_wrapper(double *p_a0, double *p_a1,
                                           double *p_a2, double *p_a3,
                                           int x_size, int y_size) {
  double p_a3_0 = p_a3[0];
#ifdef OPS_GPU
#pragma acc parallel deviceptr(p_a0, p_a1, p_a2) reduction(+ : p_a3_0)
#pragma acc loop reduction(+ : p_a3_0)
#endif
  for (int n_y = 0; n_y < y_size; n_y++) {
#ifdef OPS_GPU
#pragma acc loop reduction(+ : p_a3_0)
#endif
    for (int n_x = 0; n_x < x_size; n_x++) {
      tea_leaf_ppcg_reduce_kernel(
          p_a0 + n_x * 1 * 1 + n_y * xdim0_tea_leaf_ppcg_reduce_kernel * 1 * 1,
          p_a1 + n_x * 1 * 1 + n_y * xdim1_tea_leaf_ppcg_reduce_kernel * 1 * 1,
          p_a2 + n_x * 1 * 1 + n_y * xdim2_tea_leaf_ppcg_reduce_kernel * 1 * 1,
          &p_a3_0);
    }
  }
  p_a3[0] = p_a3_0;
}
